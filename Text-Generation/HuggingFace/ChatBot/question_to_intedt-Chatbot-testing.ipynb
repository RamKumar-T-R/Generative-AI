{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1qVzMxHiX4mRI4a4yzEuipA6ZYlSWwZgF","authorship_tag":"ABX9TyNjyK968Pq8Mg9cYTtL9Ja8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"id":"ohPAx6j10WlH","executionInfo":{"status":"ok","timestamp":1703220942588,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ram Kumar","userId":"06561407308292638687"}}},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","import joblib\n","import numpy as np"]},{"cell_type":"code","source":["model = load_model('/content/drive/MyDrive/Colab Notebooks/GEN_AI-Intern/Text-Generation/ChatBot/ques_to_intend.h5')\n","encoder = joblib.load('/content/drive/MyDrive/Colab Notebooks/GEN_AI-Intern/Text-Generation/ChatBot/encoder.pkl')\n","tokenizer = joblib.load('/content/drive/MyDrive/Colab Notebooks/GEN_AI-Intern/Text-Generation/ChatBot/tokenizer.pkl')"],"metadata":{"id":"KKVbU1vw0-HQ","executionInfo":{"status":"ok","timestamp":1703220942589,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ram Kumar","userId":"06561407308292638687"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["import json\n","ans_database = open('/content/drive/MyDrive/Colab Notebooks/GEN_AI-Intern/Text-Generation/ChatBot/Ans_data.txt').read()\n","ans_database = ans_database.replace(\"'\", \"\\\"\")"],"metadata":{"id":"StpSIZIi1YuG","executionInfo":{"status":"ok","timestamp":1703220942589,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ram Kumar","userId":"06561407308292638687"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["ans_database = json.loads(ans_database)"],"metadata":{"id":"5ATggaec1_XZ","executionInfo":{"status":"ok","timestamp":1703220942589,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ram Kumar","userId":"06561407308292638687"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["intent = list(ans_database.keys())"],"metadata":{"id":"5wxsNuyk2VFb","executionInfo":{"status":"ok","timestamp":1703220942590,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ram Kumar","userId":"06561407308292638687"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"metadata":{"id":"DWs5i07g2diN","executionInfo":{"status":"ok","timestamp":1703220942590,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ram Kumar","userId":"06561407308292638687"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["while True:\n","  que = input('You:   ')\n","\n","  if que == \"exit\":\n","    print(\"Thankyou for your time. It's a gread conversation with you \")\n","    break\n","\n","  tok_data = tokenizer.texts_to_sequences(que)\n","\n","  pad_seq = pad_sequences(tok_data, maxlen = 10)\n","  pred = model.predict(pad_seq)\n","\n","  out_max = np.zeros_like(pred)\n","  for i in range(pred.shape[0]):\n","    out = np.argmax(pred[i])\n","    out_max[i][out] = 1\n","\n","  intend = encoder.inverse_transform(out_max)[0][0]\n","  print(intend)\n","\n","  # Fetching the answer with intend\n","  answer = np.random.choice(ans_database[intend])\n","\n","  print('Awesome bot:   ', answer)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNiaIJER2owJ","executionInfo":{"status":"ok","timestamp":1703221295765,"user_tz":-330,"elapsed":92644,"user":{"displayName":"Ram Kumar","userId":"06561407308292638687"}},"outputId":"d7ad538d-0dcb-41eb-bc19-cdeb417ce1b9"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["You:   hi\n","1/1 [==============================] - 0s 20ms/step\n","greetings\n","Awesome bot:    Hello Good Day\n","You:   exit\n","Thankyou for your time. It's a gread conversation with you \n"]}]},{"cell_type":"markdown","source":["Deploying in local server (run in spyder)"],"metadata":{"id":"3QeS8gFC-0W7"}},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 22 10:36:35 2023\n","\n","@author: Ramkumar\n","\"\"\"\n","\n","from flask import Flask, request\n","import joblib\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import json\n","import numpy as np\n","\n","model = load_model(\"C:/Users/Ramkumar/Downloads/ques_to_intend.h5\")\n","encoder = joblib.load(\"C:/Users/Ramkumar/Downloads/encoder.pkl\")\n","tokenizer = joblib.load(\"C:/Users/Ramkumar/Downloads/tokenizer.pkl\")\n","\n","ans_database = open(\"C:/Users/Ramkumar/Downloads/Ans_data.txt\").read()\n","ans_database = ans_database.replace(\"'\", \"\\\"\")\n","ans_database = json.loads(ans_database)\n","\n","app = Flask(__name__)\n","@app.route('/', methods=['POST'])\n","\n","def prediction():\n","    que = input('You:   ')\n","\n","    if que == \"exit\":\n","      print(\"Thankyou for your time. It's a gread conversation with you \")\n","\n","    tok_data = tokenizer.texts_to_sequences(que)\n","\n","    pad_seq = pad_sequences(tok_data, maxlen = 10)\n","    pred = model.predict(pad_seq)\n","\n","    out_max = np.zeros_like(pred)\n","    for i in range(pred.shape[0]):\n","      out = np.argmax(pred[i])\n","      out_max[i][out] = 1\n","\n","    intend = encoder.inverse_transform(out_max)[0][0]\n","    print(intend)\n","\n","    # Fetching the answer with intend\n","    answer = np.random.choice(ans_database[intend])\n","\n","    print('Awesome bot:   ', answer)\n","    return 'Awesome bot:   ' + answer\n","\n","app.run(host='0.0.0.0')\n"],"metadata":{"id":"wnDD_Ucv6gJL"},"execution_count":null,"outputs":[]}]}